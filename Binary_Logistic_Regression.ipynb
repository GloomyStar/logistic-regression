{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Binary-Logistic-Regression.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sthalles/logistic-regression/blob/master/Binary_Logistic_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "ruxWlF98VBHA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from numpy.linalg import pinv, inv\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uwrCd56g_tn-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class DataSet:\n",
        "  def __init__(self, data, targets, valid_classes=None):\n",
        "    if valid_classes is None:\n",
        "      self.valid_classes = np.unique(targets)\n",
        "    else:\n",
        "      self.valid_classes = valid_classes\n",
        "    #print(self.valid_classes)\n",
        "    self.number_of_classes = len(self.valid_classes)\n",
        "    self.data = self.to_dict(data, targets)\n",
        "    \n",
        "    total = 0\n",
        "    for i in self.data.keys():\n",
        "      print(\"Class {0} # of records: {1}\".format(i,len(self.data[i])))\n",
        "      total += len(self.data[i])\n",
        "    print(\"Total:\",total)\n",
        "    \n",
        "  def to_dict(self, data, targets):\n",
        "    data_dict = {}\n",
        "    for x, y in zip(data, targets):\n",
        "      if y in self.valid_classes:\n",
        "        if y not in data_dict:\n",
        "          data_dict[y] = [x.flatten()]\n",
        "        else:\n",
        "          data_dict[y].append(x.flatten())\n",
        "\n",
        "    for i in self.valid_classes:\n",
        "      data_dict[i] = np.asarray(data_dict[i])\n",
        "\n",
        "    return data_dict\n",
        "\n",
        "  def get_data_by_class(self, class_id):\n",
        "    if class_id in self.valid_classes:\n",
        "      return self.data[class_id]\n",
        "    else:\n",
        "      raise (\"Class not found.\")\n",
        "\n",
        "  def get_data_as_dict(self):\n",
        "    return self.data\n",
        "\n",
        "  def get_all_data(self):\n",
        "    data = []\n",
        "    labels = []\n",
        "    for label, class_i_data in self.data.items():\n",
        "      data.extend(class_i_data)\n",
        "      labels.extend(class_i_data.shape[0] * [label])\n",
        "    data = np.asarray(data)\n",
        "    labels = np.asarray(labels)\n",
        "    return data, np.expand_dims(labels,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_eXm_xdpVJ6v",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XYuDfAtYM1hc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iC6Bv_9r-1QW",
        "colab_type": "code",
        "outputId": "ca4be4af-8209-4804-9f32-fe513d5c6c89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "cell_type": "code",
      "source": [
        "train_dataset = DataSet(x_train, y_train, valid_classes=[0,1])\n",
        "inputs, targets = train_dataset.get_all_data()\n",
        "\n",
        "test_dataset = DataSet(x_test, y_test, valid_classes=[0,1])\n",
        "test_inputs, test_targets = test_dataset.get_all_data()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Class 0 # of records: 5923\n",
            "Class 1 # of records: 6742\n",
            "Total: 12665\n",
            "Class 1 # of records: 1135\n",
            "Class 0 # of records: 980\n",
            "Total: 2115\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Uow9yEhKWOsr",
        "colab_type": "code",
        "outputId": "63a17d76-d0c3-4c4e-b562-b69a2cc7f568",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"inputs shape:\",inputs.shape)\n",
        "print(\"targets shape:\",targets.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "inputs shape: (12665, 784)\n",
            "targets shape: (12665, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vk0WRmnxV8ES",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "- For an M-dimensional feature space φ, this model has M adjustable parameters\n"
      ]
    },
    {
      "metadata": {
        "id": "ugPAPSamVqcs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def generate_R(predictions):\n",
        "  # N × N diagonal matrix R with elements Rnn = yn(1−yn)\n",
        "  R = np.zeros((predictions.shape[0],predictions.shape[0]))\n",
        "  for i in range(R.shape[0]):\n",
        "    #print(predictions[i])\n",
        "    R[i][i] = predictions[i] * (1-predictions[i])\n",
        "  return R\n",
        "\n",
        "def hessian(x,R):\n",
        "  return np.dot(x.T,np.dot(R,x))\n",
        "    \n",
        "def grad(y,t,x):\n",
        "  # y: models predictions (Batch,)\n",
        "  # t: dataset targets (Batch,)\n",
        "  return np.dot(x.T, (y - t))\n",
        "  \n",
        "  \n",
        "class LogisticRegression:\n",
        "  def __init__(self,fit_intercept=True):\n",
        "    self.fit_intercept = fit_intercept\n",
        "    self.W = None\n",
        "    \n",
        "  \n",
        "  def score(self,x,y):\n",
        "    \n",
        "    if self.fit_intercept:\n",
        "      x = self.add_intercept(x)    \n",
        "      \n",
        "    logits = self.forward(x)\n",
        "    predictions = [1 if t >= 0.5 else 0 for t in logits]\n",
        "#     print(\"predictions:\",predictions)\n",
        "#     print(\"targets:\",y)\n",
        "    return np.sum(np.squeeze(predictions) == np.squeeze(y)) / len(y)\n",
        "\n",
        "  def sigmoid(self,x):\n",
        "    # Under rather general assumptions, the posterior probability of class C1 can be written \n",
        "    # as a logistic sigmoid acting on a linear function of the feature vector φ so that\n",
        "    return 1. / (1. + np.exp(-x))\n",
        "    \n",
        "  def forward(self,x):\n",
        "    \n",
        "    if self.W is None:\n",
        "      self.W = np.full((x.shape[1],1), 0.01) #np.random.rand(x.shape[1],1)\n",
        "      print(\"W.shape\",self.W.shape)\n",
        "    linear = np.dot(x,self.W)\n",
        "    \n",
        "    print(\"Weights: Min: {0} Max: {1}\".format(np.min(self.W), np.max(self.W)))\n",
        "    print(\"Probabilities: Min: {0} Max: {1}\".format(np.min(linear), np.max(linear)))\n",
        "    return self.sigmoid(linear) # the order dot(x,W) seems correct\n",
        "\n",
        "  def add_intercept(self,x):\n",
        "    # generate a NxM design matrix, with an added column of 1\n",
        "    const = np.ones((x.shape[0],1))\n",
        "    return np.concatenate((const,x),axis=1)\n",
        "\n",
        "  def fit(self,x,y,iterations=2):\n",
        "    \n",
        "    if self.fit_intercept:\n",
        "      x = self.add_intercept(x)\n",
        "      \n",
        "    for i in range(iterations):\n",
        "      predictions = self.forward(x)\n",
        "      R = generate_R(predictions)\n",
        "      H = hessian(x,R)\n",
        "      print(\"Hessian:\",H.shape)\n",
        "      gradients = grad(predictions,y,x)\n",
        "      invH = pinv(H)\n",
        "      #W_new = self.W - 0.2 * gradients\n",
        "      self.W = self.W - np.dot(invH, gradients)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "h_jtcdkEXYEm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "clf = LogisticRegression(fit_intercept=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "q8ejl19QXE8D",
        "colab_type": "code",
        "outputId": "e124ee01-7325-4c7b-afe3-fbd4d35157a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "cell_type": "code",
      "source": [
        "BATCH_SIZE=inputs.shape[0]\n",
        "inputs = inputs[:BATCH_SIZE,]\n",
        "targets = targets[:BATCH_SIZE,]\n",
        "print(inputs.shape, targets.shape)\n",
        "logits = clf.forward(inputs)\n",
        "print(\"logits.shape:\",logits.shape)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(12665, 784) (12665, 1)\n",
            "W.shape (784, 1)\n",
            "Weights: Min: 0.01 Max: 0.01\n",
            "Probabilities: Min: 0.19945098039215686 Max: 3.1169803921568593\n",
            "logits.shape: (12665, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "67w28DPic-nQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "- Uses the Newton-Raphson iterative optimization scheme to optimize the values of W"
      ]
    },
    {
      "metadata": {
        "id": "d69QzOUjevJ0",
        "colab_type": "code",
        "outputId": "87be23b4-80ad-4250-bee7-c3fbedd2f041",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "R = generate_R(logits)\n",
        "print(R.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(12665, 12665)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OyIhoEzOeyyn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# H1 = hessian(inputs,R)\n",
        "# print(\"H1.shape:\",H1.shape)\n",
        "# print(np.nonzero(H1))\n",
        "\n",
        "# H2 = hessian_2(batch_x,R)\n",
        "# print(np.nonzero(H2))\n",
        "# print(H1.shape,H2.shape)\n",
        "\n",
        "# print(\"Following the associativity property, H1 and H2 should be equal\")\n",
        "# print(np.all(H1 == H2)) # True (problelm with precision though)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4mADP-HLj1dI",
        "colab_type": "code",
        "outputId": "ce4c0fe8-76fb-4088-b50a-af9c6f2b3cae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "gradients = grad(logits,targets,inputs)\n",
        "print(\"grads.shape:\",gradients.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "grads.shape: (784, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "EvNP8mbSkByh",
        "colab_type": "code",
        "outputId": "800a2a74-9a72-4c61-bbdb-6d6ef3de6e88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Note that the predictions, are always between 0 and 1 - due to the sigmoid function squashing\n",
        "print(np.min(logits),np.max(logits))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5496981021461362 0.957587760803051\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cL0IfcyGx9Az",
        "colab_type": "code",
        "outputId": "16d201ad-9981-4d00-c44f-cf5c06a269ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "cell_type": "code",
      "source": [
        "clf = LogisticRegression(fit_intercept=True)\n",
        "clf.fit(inputs,targets)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W.shape (785, 1)\n",
            "Weights: Min: 0.01 Max: 0.01\n",
            "Probabilities: Min: 0.20945098039215687 Max: 3.1269803921568595\n",
            "Hessian: (785, 785)\n",
            "Weights: Min: -131.2646916891356 Max: 73.5545290216585\n",
            "Probabilities: Min: -9.67115827495726 Max: 3.361295299510244\n",
            "Hessian: (785, 785)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "chpngsbr1xEQ",
        "colab_type": "code",
        "outputId": "4c4306c8-a32e-46c8-8d24-4970ac76ed7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "acc = clf.score(inputs,targets)\n",
        "print(acc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Weights: Min: -95.13851871653901 Max: 53.394425209318584\n",
            "Probabilities: Min: -12.680541874001982 Max: 5.392235406124617\n",
            "0.9996052112120016\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Vcvwpi-21xHm",
        "colab_type": "code",
        "outputId": "6a9f4ab9-f9cc-4b0c-fd44-93224c7753ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "acc = clf.score(test_inputs,test_targets)\n",
        "print(acc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Weights: Min: -95.13851871653901 Max: 53.394425209318584\n",
            "Probabilities: Min: -10.969357161091907 Max: 38.2660259135658\n",
            "0.9985815602836879\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}